# Secrets Configuration Template
# =============================
# 이 파일을 secrets.yaml로 복사하고 실제 인증 정보를 입력하세요.
#
# 중요: secrets.yaml은 .gitignore에 포함되어 절대 커밋되지 않습니다.
#
# 우선순위: 환경 변수 > secrets.yaml > settings.yaml

# LLM API 인증 정보
llm:
  generator:
    # 질문/답변 생성용 API 키
    api_key: "your-api-key-here"

    # 선택: 커스텀 엔드포인트 사용 시 base_url 오버라이드
    # base_url: "https://api.openai.com/v1"

  judge:
    # 평가용 API 키 (generator와 동일하거나 다를 수 있음)
    api_key: "your-api-key-here"

    # 선택: base_url 오버라이드
    # base_url: "https://api.openai.com/v1"

# HuggingFace 토큰 (CGIAR 데이터셋 접근용)
huggingface:
  token: "your-hf-token-here"

# MQM 판정 모델 (선택 - 기본 llm.judge와 다른 경우)
# mqm:
#   judges:
#     - name: "claude"
#       base_url: "https://api.openai.com/v1"
#       model: "claude-sonnet-4-5"
#       api_key: "your-claude-key-here"
#       temperature: 0.0
#       max_tokens: 1200
#     - name: "gemini"
#       base_url: "https://api.openai.com/v1"
#       model: "gemini-2.5-pro"
#       api_key: "your-gemini-key-here"
#       temperature: 0.0
#       max_tokens: 1200

# 참고 사항:
# ----------
# 1. 이 파일 대신 환경 변수를 사용할 수도 있습니다:
#    - API_KEY 또는 OPENAI_API_KEY: LLM 인증 정보
#    - OPENAI_BASE_URL 또는 API_BASE_URL: 엔드포인트
#    - HF_TOKEN 또는 HUGGINGFACE_HUB_TOKEN: HuggingFace
#
# 2. 환경 변수가 최우선 적용되어 이 파일의 값을 오버라이드합니다.
#
# 3. 개발 시 프로젝트 루트의 .env 파일 사용 가능:
#    export API_KEY="your-key"
#    export OPENAI_BASE_URL="https://api.openai.com/v1"
